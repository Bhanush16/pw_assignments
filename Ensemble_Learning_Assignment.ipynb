{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Theoretical Questions\n",
        "\n"
      ],
      "metadata": {
        "id": "6gk0a76D5qZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###**1. Can we use Bagging for regression problems?**Yes, we absolutely can. The method is called **Bagging Regressor**.\n",
        "\n",
        "* Instead of training base classifiers (like Decision Tree Classifiers) to predict a class, it trains **base regressors** (like Decision Tree Regressors) to predict a continuous value.\n",
        "* The final prediction is typically the **average** of the predictions made by all the individual regressors in the ensemble.\n",
        "\n",
        "###**2. What is the difference between multiple model training and single model training?**| Feature | Single Model Training | Multiple Model Training (Ensemble) |\n",
        "| --- | --- | --- |\n",
        "| **Goal** | Optimize a single model's performance. | Combine predictions from several base models to improve overall performance and robustness. |\n",
        "| **Bias/Variance** | Can suffer from high bias (underfitting) or high variance (overfitting). | Aims to reduce variance (Bagging) or bias (Boosting) by combining models. |\n",
        "| **Complexity** | Generally simpler, faster to train and interpret. | More complex, slower to train (multiple models) and harder to interpret. |\n",
        "| **Prediction** | Single prediction from one model. | Combined prediction (e.g., average, majority vote) from multiple models. |\n",
        "| **Robustness** | Less robust to noise and fluctuations in the training data. | More robust and stable due to the aggregation of diverse models. |\n",
        "\n",
        "###**3. Explain the concept of feature randomness in Random Forest.**Feature randomness, also known as **random subspace method** or **feature bagging**, is a key distinguishing factor of Random Forest from standard Bagging.\n",
        "\n",
        "* **Process:** When building *each* individual decision tree in the forest, instead of searching across *all* features to find the best split at each node, the algorithm only considers a random subset of the features.\n",
        "* **Hyperparameter:** The size of this random subset is controlled by a hyperparameter, often denoted as m or `max_features` (e.g., typically \\sqrt{p} for classification and p/3 for regression, where p is the total number of features).\n",
        "* **Effect:** This step further **decorrelates** the individual trees. If there is one very strong predictor feature, standard Bagging trees would all pick it early on, making them highly similar. By only allowing a random subset of features, we force the trees to be more diverse, which is crucial for reducing the final ensemble's variance.\n",
        "\n",
        "###**4. What is OOB (Out-of-Bag) Score?**The Out-of-Bag (OOB) score is a way to estimate the performance of a Bagging-based ensemble model (like Random Forest) **without the need for a separate validation set**.\n",
        "\n",
        "* **Out-of-Bag Samples:** Due to bootstrap sampling, each base model (tree) in the ensemble is trained on a unique subset of the training data. The data points that **were not included** in the bootstrap sample for a specific tree are called the **Out-of-Bag (OOB) samples** for that tree. Typically, about **37%** of the original training data are OOB for any given tree.\n",
        "* **OOB Score Calculation:**\n",
        "1. For each training data point, identify the subset of trees for which this data point was an OOB sample.\n",
        "2. The final OOB prediction for that data point is the average (regression) or majority vote (classification) of only those trees.\n",
        "3. The OOB Score is the overall accuracy (classification) or R^2/MSE (regression) of these OOB predictions on the training set.\n",
        "\n",
        "\n",
        "\n",
        "This score provides an internal, unbiased estimate of the model's generalization performance.\n",
        "\n",
        "###**5. How can you measure the importance of features in a Random Forest model?**Random Forest inherently provides a robust way to estimate feature importance, most commonly measured using **Mean Decrease in Impurity (MDI)** or **Gini Importance**.\n",
        "\n",
        "* **Principle:** When a node in a decision tree is split using a particular feature, the impurity (e.g., Gini impurity or entropy for classification, or variance for regression) of the resulting child nodes is generally less than the parent node. The **total decrease in impurity** contributed by a feature, averaged across all the trees in the forest, is its importance score.\n",
        "* **Interpretation:** A higher importance score indicates that the feature was used more frequently and effectively to split the nodes, leading to greater homogeneity in the resulting subsets (i.e., it was a better predictor).\n",
        "\n",
        "###**6. Explain the working principle of a Bagging Classifier?**The working principle of a Bagging Classifier (Bootstrap Aggregating) is as follows:\n",
        "\n",
        "1. **Bootstrap Sampling:** The algorithm generates N new training datasets by **sampling with replacement** (bootstrapping) from the original training dataset. Each new dataset is approximately the same size as the original but contains duplicate instances and omits some original instances (OOB samples).\n",
        "2. **Base Model Training:** A base classifier (e.g., Decision Tree, which is often a **high-variance, low-bias** model) is trained independently on each of the N bootstrap samples.\n",
        "3. **Aggregation (Voting):** To make a final prediction for a new instance, all N individual classifiers make their own prediction. The final classification is determined by the **majority vote** (or mode) of the predictions from all the base classifiers.\n",
        "\n",
        "###**7. How do you evaluate a Bagging Classifierâ€™s performance?**A Bagging Classifier's performance is typically evaluated using standard machine learning metrics on a **held-out test set** or via its **OOB Score**.\n",
        "\n",
        "* **Using a Test Set:**\n",
        "* **Classification Metrics:** Accuracy, Precision, Recall, F1-Score, AUC-ROC.\n",
        "\n",
        "\n",
        "* **Using OOB Score (Internal Validation):**\n",
        "* As described in question 4, the OOB score provides a good estimate of generalization without partitioning the training data.\n",
        "\n",
        "\n",
        "\n",
        "###**8. How does a Bagging Regressor work?**The working of a Bagging Regressor is nearly identical to a Bagging Classifier, with one key difference in the aggregation step:\n",
        "\n",
        "1. **Bootstrap Sampling:** Same as in classification.\n",
        "2. **Base Regressor Training:** A base regressor (e.g., Decision Tree Regressor) is trained on each bootstrap sample.\n",
        "3. **Aggregation (Averaging):** To make a final prediction for a new instance, all individual regressors make a prediction of a continuous value. The final prediction is the **average** (mean) of all the individual predictions.\n",
        "\n",
        "###**9. What is the main advantage of ensemble techniques?**The main advantage of ensemble techniques is their ability to significantly **improve the stability and accuracy** of a model compared to any single base model, primarily by **reducing variance** (Bagging/Random Forest) or **reducing bias** (Boosting).\n",
        "\n",
        "###**10. What is the main challenge of ensemble methods?**The main challenge of ensemble methods is **reduced interpretability** and **increased computational cost/time**.\n",
        "\n",
        "* **Interpretability:** Since the final prediction is the result of many models interacting, it becomes much harder to understand *why* a particular prediction was made (the \"black box\" problem).\n",
        "* **Computational Cost:** Training and storing multiple base models (sometimes hundreds or thousands) can be significantly more time-consuming and memory-intensive than training a single model.\n",
        "\n",
        "###**11. Explain the key idea behind ensemble techniques?**The key idea behind ensemble techniques is that a **collection of weak or mediocre models can collectively form a powerful model** that is more accurate, robust, and stable than any of its individual components.\n",
        "\n",
        "This improvement relies on the base models making diverse errors. When models are diverse, their errors tend to cancel each other out during aggregation.\n",
        "\n",
        "###**12. What is a Random Forest Classifier?**A Random Forest Classifier is an ensemble learning method that is a type of **Bagging technique** specifically tailored for decision trees.\n",
        "\n",
        "* **Components:** It consists of a large number of individual decision trees that operate as an ensemble.\n",
        "* **Two Randomness Sources (Key Idea):**\n",
        "1. **Bootstrap Aggregating (Row Sampling):** Each tree is trained on a random sample of the training data (bootstrap sample).\n",
        "2. **Feature Randomness (Column Sampling):** At each split during the tree-building process, only a random subset of features is considered.\n",
        "\n",
        "\n",
        "* **Prediction:** The final classification is the **majority vote** of the individual trees.\n",
        "\n",
        "###**13. What are the main types of ensemble techniques?**The two main types of ensemble techniques are:\n",
        "\n",
        "1. **Bagging (Bootstrap Aggregating):**\n",
        "* **Goal:** Primarily to **decrease variance** and reduce overfitting.\n",
        "* **How:** Trains base models in **parallel** on different bootstrap samples of the data and aggregates their results (e.g., Random Forest, Bagging Classifier/Regressor).\n",
        "\n",
        "\n",
        "2. **Boosting:**\n",
        "* **Goal:** Primarily to **decrease bias** and transform weak learners into strong learners.\n",
        "* **How:** Trains base models **sequentially**, where each new model tries to correct the errors of the previous one (e.g., AdaBoost, Gradient Boosting, XGBoost, LightGBM).\n",
        "\n",
        "\n",
        "\n",
        "*Other types include **Stacking/Stacked Generalization** which trains a meta-model to combine the predictions of several different base models.*\n",
        "\n",
        "###**14. What is ensemble learning in machine learning?**Ensemble learning is a general meta-algorithm approach where the goal is to **combine the predictions of multiple base estimators** (e.g., classifiers or regressors) to achieve better predictive performance than could be obtained from any single base estimator.\n",
        "\n",
        "###**15. When should we avoid using ensemble methods?**While powerful, you might consider avoiding or carefully evaluating ensemble methods when:\n",
        "\n",
        "* **Interpretability is paramount:** If you need a simple, explainable model (e.g., for regulatory purposes), the \"black box\" nature of ensembles is a drawback.\n",
        "* **Computational resources are highly constrained:** Ensembles are generally slower to train and require more memory for storage.\n",
        "* **The base models are already highly correlated and accurate:** If all your base models are making the same predictions and the same errors, combining them will offer little to no benefit.\n",
        "* **Simple models are sufficient:** If a simple linear model or a single decision tree already achieves satisfactory performance, using a complex ensemble is an unnecessary overhead.\n",
        "\n",
        "###**16. How does Bagging help in reducing overfitting?**Bagging helps in reducing overfitting by **decreasing the variance** of the base models.\n",
        "\n",
        "* A single, complex model like a deep Decision Tree often has **high variance**, meaning it is highly sensitive to the specific training data and overfits to its noise.\n",
        "* Bagging trains many such models on diverse (bootstrapped) datasets.\n",
        "* When the final predictions are aggregated (averaged or voted), the variance across all the individual models is significantly reduced. The errors that were due to small fluctuations in the training data tend to **cancel each other out**, leading to a more robust, stable model that generalizes better.\n",
        "\n",
        "###**17. Why is Random Forest better than a single Decision Tree?**Random Forest is almost always better than a single, unpruned Decision Tree for three main reasons:\n",
        "\n",
        "1. **Reduced Overfitting (Lower Variance):** A single Decision Tree typically suffers from high variance (overfits the training data). Random Forest, through Bagging, significantly reduces this variance, leading to better generalization on unseen data.\n",
        "2. **Stability/Robustness:** Random Forest is more stable. Small changes in the training data can drastically alter a single Decision Tree, but they have a minimal effect on the aggregate prediction of the entire forest.\n",
        "3. **Increased Accuracy:** By combining the predictions of many diverse trees, Random Forest achieves a higher overall accuracy. The two sources of randomness (bootstrap sampling and feature randomness) ensure the trees are diverse and their errors are uncorrelated.\n",
        "\n",
        "###**18. What is the role of bootstrap sampling in Bagging?**Bootstrap sampling is the fundamental technique that makes Bagging effective. Its primary role is to **create diversity** among the base models.\n",
        "\n",
        "* **Role:** By randomly sampling the training data with replacement to create many different training subsets, bootstrap sampling ensures that each base model is trained on a slightly different view of the data.\n",
        "* **Effect:** This small difference in the training data causes the base models to make **uncorrelated errors**. This decorrelation is essential because when the models' predictions are aggregated, their independent errors cancel out, reducing the overall variance of the ensemble model.\n",
        "\n",
        "###**19. What are some real-world applications of ensemble techniques?**Ensemble techniques are widely used across various domains:\n",
        "\n",
        "* **Finance:** Credit scoring (predicting loan defaults), algorithmic trading (predicting stock movement).\n",
        "* **E-commerce:** Recommendation systems (predicting product preferences), fraud detection (identifying suspicious transactions).\n",
        "* **Healthcare/Bioinformatics:** Predicting disease outcomes, analysis of gene expression data.\n",
        "* **Image Processing/Computer Vision:** Image segmentation, object detection (e.g., using models like Mask R-CNN, which utilizes ensemble ideas).\n",
        "* **General Prediction:** Nearly all high-performance predictive modeling competitions (e.g., on Kaggle) are won using sophisticated ensemble methods like XGBoost or stacked models.\n",
        "\n",
        "###**20. What is the difference between Bagging and Boosting?**| Feature | Bagging (e.g., Random Forest) | Boosting (e.g., AdaBoost, XGBoost) |\n",
        "The core difference between Bagging and Boosting lies in their approach to training and their primary goal. Bagging (like Random Forest) trains multiple base models (often complex, high-variance Decision Trees) in parallel on independent bootstrap samples of the data. Its main objective is to reduce variance and overfitting. The final prediction is a simple average or majority vote, treating all models and data points equally. Boosting (like XGBoost), conversely, trains many simple, low-bias models (like shallow Decision Stumps) in sequence. Each new model focuses on correcting the errors of the previous ones by giving higher weight to the data points that were previously misclassified. Its main objective is to reduce bias and transform weak learners into a single, highly accurate, strong learner.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "WCpx3VFD5-wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions\n"
      ],
      "metadata": {
        "id": "jp3XoiPw8Rxy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fE8C6JKe5hYc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, mean_squared_error, roc_auc_score, confusion_matrix,\n",
        "    precision_recall_curve, auc, precision_score, recall_score, f1_score\n",
        ")\n",
        "from sklearn.datasets import load_breast_cancer, make_regression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import (\n",
        "    BaggingClassifier, BaggingRegressor, RandomForestClassifier,\n",
        "    RandomForestRegressor, StackingClassifier\n",
        ")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# --- Setup for Classification Tasks (using Breast Cancer dataset) ---\n",
        "data_cls = load_breast_cancer()\n",
        "X_cls, y_cls = data_cls.data, data_cls.target\n",
        "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the data for SVM and Logistic Regression\n",
        "scaler_cls = StandardScaler()\n",
        "X_cls_train_scaled = scaler_cls.fit_transform(X_cls_train)\n",
        "X_cls_test_scaled = scaler_cls.transform(X_cls_test)\n",
        "\n",
        "# --- Setup for Regression Tasks (using synthetic data) ---\n",
        "X_reg, y_reg = make_regression(n_samples=500, n_features=10, n_informative=5, noise=5.0, random_state=42)\n",
        "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
        "base_estimator = DecisionTreeClassifier(random_state=42)\n",
        "bag_clf_dt = BaggingClassifier(\n",
        "    estimator=base_estimator,\n",
        "    n_estimators=100,\n",
        "    max_samples=0.8,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf_dt.fit(X_cls_train, y_cls_train)\n",
        "y_pred_bag_dt = bag_clf_dt.predict(X_cls_test)\n",
        "accuracy_bag_dt = accuracy_score(y_cls_test, y_pred_bag_dt)\n",
        "\n",
        "print(f\"Bagging Classifier (DT) Accuracy: {accuracy_bag_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gNC4ei093gt",
        "outputId": "54e87b15-8c00-4f55-e646-2ab39649d445"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (DT) Accuracy: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
        "base_estimator_reg = DecisionTreeRegressor(random_state=42)\n",
        "bag_reg_dt = BaggingRegressor(\n",
        "    estimator=base_estimator_reg,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_reg_dt.fit(X_reg_train, y_reg_train)\n",
        "y_pred_bag_reg = bag_reg_dt.predict(X_reg_test)\n",
        "mse_bag_reg = mean_squared_error(y_reg_test, y_pred_bag_reg)\n",
        "\n",
        "print(f\"Bagging Regressor (DT) Mean Squared Error (MSE): {mse_bag_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7p8Qxml948_",
        "outputId": "51465b94-48eb-4d57-b7d0-be5520274d54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor (DT) Mean Squared Error (MSE): 722.3321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores\n",
        "rf_clf_importance = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf_importance.fit(X_cls_train, y_cls_train)\n",
        "\n",
        "# Print feature importance\n",
        "feature_importances = pd.Series(\n",
        "    rf_clf_importance.feature_importances_,\n",
        "    index=data_cls.feature_names\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "print(\"Random Forest Feature Importance Scores:\")\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5FCC49m96xJ",
        "outputId": "c3db0514-da18-4300-a517-3c8b13b9216f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Feature Importance Scores:\n",
            "mean concave points        0.141934\n",
            "worst concave points       0.127136\n",
            "worst area                 0.118217\n",
            "mean concavity             0.080557\n",
            "worst radius               0.077975\n",
            "worst perimeter            0.074292\n",
            "mean perimeter             0.060092\n",
            "mean area                  0.053810\n",
            "worst concavity            0.041080\n",
            "mean radius                0.032312\n",
            "area error                 0.029538\n",
            "worst texture              0.018786\n",
            "worst compactness          0.017539\n",
            "radius error               0.016435\n",
            "worst symmetry             0.012929\n",
            "perimeter error            0.011770\n",
            "worst smoothness           0.011769\n",
            "mean texture               0.011064\n",
            "mean compactness           0.009216\n",
            "fractal dimension error    0.007135\n",
            "worst fractal dimension    0.006924\n",
            "mean smoothness            0.006223\n",
            "smoothness error           0.005881\n",
            "concavity error            0.005816\n",
            "compactness error          0.004596\n",
            "symmetry error             0.004001\n",
            "concave points error       0.003382\n",
            "mean symmetry              0.003278\n",
            "texture error              0.003172\n",
            "mean fractal dimension     0.003140\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24. Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "# 1. Single Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_reg_train, y_reg_train)\n",
        "y_pred_dt_reg = dt_reg.predict(X_reg_test)\n",
        "mse_dt_reg = mean_squared_error(y_reg_test, y_pred_dt_reg)\n",
        "\n",
        "# 2. Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_reg.fit(X_reg_train, y_reg_train)\n",
        "y_pred_rf_reg = rf_reg.predict(X_reg_test)\n",
        "mse_rf_reg = mean_squared_error(y_reg_test, y_pred_rf_reg)\n",
        "\n",
        "print(f\"Single Decision Tree Regressor MSE: {mse_dt_reg:.4f}\")\n",
        "print(f\"Random Forest Regressor MSE:      {mse_rf_reg:.4f}\")\n",
        "print(f\"Random Forest is {'better' if mse_rf_reg < mse_dt_reg else 'worse'} (lower MSE is better).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjWPsLnh98fv",
        "outputId": "979acc66-14f1-4ff9-ee7f-e1e16cb78301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Regressor MSE: 1815.0080\n",
            "Random Forest Regressor MSE:      717.0599\n",
            "Random Forest is better (lower MSE is better).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "# OOB requires setting oob_score=True during training\n",
        "rf_clf_oob = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42, n_jobs=-1)\n",
        "# Note: OOB score is calculated during fit\n",
        "rf_clf_oob.fit(X_cls_train, y_cls_train)\n",
        "\n",
        "# The OOB score is available in the oob_score_ attribute\n",
        "oob_score = rf_clf_oob.oob_score_\n",
        "\n",
        "print(f\"Random Forest Classifier Out-of-Bag (OOB) Score: {oob_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ELESq0S9-Mq",
        "outputId": "50c34a4c-d5eb-45d9-82a1-313e06147300"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Out-of-Bag (OOB) Score: 0.9548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 26. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
        "# Use scaled data for SVM\n",
        "base_estimator_svm = SVC(kernel='linear', probability=True, random_state=42)\n",
        "bag_clf_svm = BaggingClassifier(\n",
        "    estimator=base_estimator_svm,\n",
        "    n_estimators=10, # Fewer estimators due to SVM's complexity\n",
        "    max_samples=0.8,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf_svm.fit(X_cls_train_scaled, y_cls_train)\n",
        "y_pred_bag_svm = bag_clf_svm.predict(X_cls_test_scaled)\n",
        "accuracy_bag_svm = accuracy_score(y_cls_test, y_pred_bag_svm)\n",
        "\n",
        "print(f\"Bagging Classifier (SVM) Accuracy: {accuracy_bag_svm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkWYItF2-ANA",
        "outputId": "a905cda1-5335-448e-92a9-6f849f7080c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (SVM) Accuracy: 0.9766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 27. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "n_estimators_list = [10, 50, 100, 200]\n",
        "results = {}\n",
        "\n",
        "print(\"Random Forest Accuracy Comparison by Number of Trees:\")\n",
        "for n in n_estimators_list:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n",
        "    rf_clf.fit(X_cls_train, y_cls_train)\n",
        "    y_pred = rf_clf.predict(X_cls_test)\n",
        "    accuracy = accuracy_score(y_cls_test, y_pred)\n",
        "    results[n] = accuracy\n",
        "    print(f\"N_estimators={n:3}: Accuracy={accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD9m6LQ7-Bzy",
        "outputId": "89190cad-2b4b-4043-e473-7ae57d368b55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy Comparison by Number of Trees:\n",
            "N_estimators= 10: Accuracy=0.9649\n",
            "N_estimators= 50: Accuracy=0.9708\n",
            "N_estimators=100: Accuracy=0.9708\n",
            "N_estimators=200: Accuracy=0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
        "# Use scaled data for Logistic Regression\n",
        "base_estimator_lr = LogisticRegression(solver='liblinear', random_state=42)\n",
        "bag_clf_lr = BaggingClassifier(\n",
        "    estimator=base_estimator_lr,\n",
        "    n_estimators=10,\n",
        "    max_samples=0.8,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_clf_lr.fit(X_cls_train_scaled, y_cls_train)\n",
        "\n",
        "# Get probability scores for AUC\n",
        "y_proba_bag_lr = bag_clf_lr.predict_proba(X_cls_test_scaled)[:, 1]\n",
        "auc_bag_lr = roc_auc_score(y_cls_test, y_proba_bag_lr)\n",
        "\n",
        "print(f\"Bagging Classifier (LR) ROC-AUC Score: {auc_bag_lr:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vZCa1zn-De8",
        "outputId": "1a8178e4-e810-4af6-d8f8-98f27952b9f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (LR) ROC-AUC Score: 0.9975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 29. Train a Random Forest Regressor and analyze feature importance scores\n",
        "rf_reg_importance = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_reg_importance.fit(X_reg_train, y_reg_train)\n",
        "\n",
        "# Feature names are synthetic, so we use indices\n",
        "reg_feature_names = [f'Feature_{i}' for i in range(X_reg.shape[1])]\n",
        "feature_importances_reg = pd.Series(\n",
        "    rf_reg_importance.feature_importances_,\n",
        "    index=reg_feature_names\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "print(\"Random Forest Regressor Feature Importance Scores:\")\n",
        "print(feature_importances_reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inJyEl3Z-E7m",
        "outputId": "869b2c1b-06fd-48f8-e9b4-58f9fa00ee29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Feature Importance Scores:\n",
            "Feature_6    0.543379\n",
            "Feature_7    0.129270\n",
            "Feature_0    0.126948\n",
            "Feature_2    0.084249\n",
            "Feature_8    0.055793\n",
            "Feature_3    0.014527\n",
            "Feature_4    0.013798\n",
            "Feature_1    0.011896\n",
            "Feature_5    0.010505\n",
            "Feature_9    0.009636\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "# 1. Bagging Classifier (DT) - using the result from Q21\n",
        "accuracy_bagging = accuracy_bag_dt\n",
        "\n",
        "# 2. Random Forest Classifier\n",
        "rf_clf_comp = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf_comp.fit(X_cls_train, y_cls_train)\n",
        "y_pred_rf_comp = rf_clf_comp.predict(X_cls_test)\n",
        "accuracy_rf = accuracy_score(y_cls_test, y_pred_rf_comp)\n",
        "\n",
        "print(f\"Bagging Classifier (DT) Accuracy:  {accuracy_bagging:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {accuracy_rf:.4f}\")\n",
        "print(f\"Comparison suggests Random Forest is {'better' if accuracy_rf > accuracy_bagging else 'worse'} (higher accuracy is better).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ0jLQgr-GM0",
        "outputId": "c801c2f8-be5b-480f-cae0-fc8ccec909a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (DT) Accuracy:  0.9591\n",
            "Random Forest Classifier Accuracy: 0.9708\n",
            "Comparison suggests Random Forest is better (higher accuracy is better).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "rf_clf_base = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_clf_base,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(X_cls_train, y_cls_train)\n",
        "\n",
        "print(f\"Best Hyperparameters for RF: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "best_rf_clf = grid_search.best_estimator_\n",
        "y_pred_grid = best_rf_clf.predict(X_cls_test)\n",
        "test_accuracy_grid = accuracy_score(y_cls_test, y_pred_grid)\n",
        "print(f\"Test Set Accuracy with Best RF Model: {test_accuracy_grid:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt-XYRPY-HrC",
        "outputId": "22867c85-85ed-42c6-b51c-1c5f9a56df3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for RF: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Best Cross-Validation Accuracy: 0.9623\n",
            "Test Set Accuracy with Best RF Model: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
        "n_estimators_reg_list = [10, 50, 100, 200]\n",
        "reg_results_n = {}\n",
        "base_reg = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "print(\"Bagging Regressor MSE Comparison by Number of Estimators:\")\n",
        "for n in n_estimators_reg_list:\n",
        "    bag_reg_n = BaggingRegressor(estimator=base_reg, n_estimators=n, n_jobs=-1, random_state=42)\n",
        "    bag_reg_n.fit(X_reg_train, y_reg_train)\n",
        "    y_pred = bag_reg_n.predict(X_reg_test)\n",
        "    mse = mean_squared_error(y_reg_test, y_pred)\n",
        "    reg_results_n[n] = mse\n",
        "    print(f\"N_estimators={n:3}: MSE={mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orOfL_yK-I9G",
        "outputId": "6e0e15a9-7839-48f9-9cba-93f797516b95"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE Comparison by Number of Estimators:\n",
            "N_estimators= 10: MSE=743.4460\n",
            "N_estimators= 50: MSE=704.9520\n",
            "N_estimators=100: MSE=722.3321\n",
            "N_estimators=200: MSE=703.8134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 33. Train a Random Forest Classifier and analyze misclassified samples\n",
        "rf_clf_analysis = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf_analysis.fit(X_cls_train, y_cls_train)\n",
        "y_pred_analysis = rf_clf_analysis.predict(X_cls_test)\n",
        "\n",
        "# Identify misclassified indices\n",
        "misclassified_indices = np.where(y_cls_test != y_pred_analysis)[0]\n",
        "\n",
        "print(f\"Total test samples: {len(y_cls_test)}\")\n",
        "print(f\"Total misclassified samples: {len(misclassified_indices)}\")\n",
        "\n",
        "if len(misclassified_indices) > 0:\n",
        "    print(\"Details of the first 5 misclassified samples:\")\n",
        "    for i, idx in enumerate(misclassified_indices[:5]):\n",
        "        true_label = data_cls.target_names[y_cls_test[idx]]\n",
        "        pred_label = data_cls.target_names[y_pred_analysis[idx]]\n",
        "        print(f\"  Sample Index (Test Set): {idx}, True Label: {true_label}, Predicted Label: {pred_label}\")\n",
        "else:\n",
        "    print(\"No misclassified samples found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hsbyul3-KJK",
        "outputId": "8e671037-ffc8-48e4-ebed-a940e14ad32f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total test samples: 171\n",
            "Total misclassified samples: 5\n",
            "Details of the first 5 misclassified samples:\n",
            "  Sample Index (Test Set): 8, True Label: benign, Predicted Label: malignant\n",
            "  Sample Index (Test Set): 20, True Label: malignant, Predicted Label: benign\n",
            "  Sample Index (Test Set): 77, True Label: malignant, Predicted Label: benign\n",
            "  Sample Index (Test Set): 82, True Label: malignant, Predicted Label: benign\n",
            "  Sample Index (Test Set): 164, True Label: malignant, Predicted Label: benign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
        "# 1. Single Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_cls_train, y_cls_train)\n",
        "y_pred_dt = dt_clf.predict(X_cls_test)\n",
        "accuracy_dt = accuracy_score(y_cls_test, y_pred_dt)\n",
        "\n",
        "# 2. Bagging Classifier (DT) - using the result from Q21\n",
        "accuracy_bagging = accuracy_bag_dt\n",
        "\n",
        "print(f\"Single Decision Tree Classifier Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Bagging Classifier (DT) Accuracy:        {accuracy_bagging:.4f}\")\n",
        "print(f\"Bagging is {'better' if accuracy_bagging > accuracy_dt else 'worse'} (higher accuracy is better) than a single, unpruned DT.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOY-V6_W-Lqv",
        "outputId": "83bf2d1c-36bf-4c92-c427-254f1b06e9d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Classifier Accuracy: 0.9415\n",
            "Bagging Classifier (DT) Accuracy:        0.9591\n",
            "Bagging is better (higher accuracy is better) than a single, unpruned DT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 35. Train a Random Forest Classifier and visualize the confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "rf_clf_cm = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf_cm.fit(X_cls_train, y_cls_train)\n",
        "y_pred_cm = rf_clf_cm.predict(X_cls_test)\n",
        "\n",
        "cm = confusion_matrix(y_cls_test, y_pred_cm)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "# Print the raw matrix\n",
        "print(cm)\n",
        "\n",
        "# Plotting the matrix (requires a plot window)\n",
        "try:\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data_cls.target_names)\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
        "    plt.title(\"Random Forest Confusion Matrix\")\n",
        "    # plt.show() # Uncomment to display the plot\n",
        "    print(\"Confusion Matrix plot generated (requires plt.show() to display in a non-interactive environment).\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not display plot due to environment issue (e.g., missing GUI): {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "Rau8PP2D-M4_",
        "outputId": "0a663e18-3436-4d24-8e4b-dd18d2266e45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 59   4]\n",
            " [  1 107]]\n",
            "Confusion Matrix plot generated (requires plt.show() to display in a non-interactive environment).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
        "# Base estimators need the scaled data for SVM and LR, but the StackingClassifier handles the fit transformation internally if needed.\n",
        "# We will use the already scaled data for fairness.\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42)),\n",
        "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
        "]\n",
        "\n",
        "# The final estimator (meta-model)\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(random_state=42),\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "stack_clf.fit(X_cls_train_scaled, y_cls_train)\n",
        "y_pred_stack = stack_clf.predict(X_cls_test_scaled)\n",
        "accuracy_stack = accuracy_score(y_cls_test, y_pred_stack)\n",
        "\n",
        "# Compare with the Bagging DT accuracy from Q21\n",
        "print(f\"Stacking Classifier Accuracy: {accuracy_stack:.4f}\")\n",
        "print(f\"Bagging Classifier (DT) Accuracy: {accuracy_bag_dt:.4f}\")\n",
        "print(f\"Stacking is {'better' if accuracy_stack > accuracy_bag_dt else 'worse'} in this comparison.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92kWR55r-ODA",
        "outputId": "fde18aaf-f4ee-484c-d8aa-3b40c7d747e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9825\n",
            "Bagging Classifier (DT) Accuracy: 0.9591\n",
            "Stacking is better in this comparison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 37. Train a Random Forest Classifier and print the top 5 most important features\n",
        "# Use the feature importances calculated in Q23\n",
        "top_5_features = feature_importances.head(5)\n",
        "print(\"Top 5 Most Important Features in Random Forest:\")\n",
        "print(top_5_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bRSAxPj-Pi8",
        "outputId": "544f6ae9-6f1e-4ae9-cb29-b7b0a9659b0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features in Random Forest:\n",
            "mean concave points     0.141934\n",
            "worst concave points    0.127136\n",
            "worst area              0.118217\n",
            "mean concavity          0.080557\n",
            "worst radius            0.077975\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "# Use the trained Bagging Classifier and predictions from Q21\n",
        "y_pred_bag_dt = bag_clf_dt.predict(X_cls_test)\n",
        "precision = precision_score(y_cls_test, y_pred_bag_dt)\n",
        "recall = recall_score(y_cls_test, y_pred_bag_dt)\n",
        "f1 = f1_score(y_cls_test, y_pred_bag_dt)\n",
        "\n",
        "print(f\"Bagging Classifier (DT) Metrics:\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"  F1-Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TPA2kOE-RcR",
        "outputId": "3a2e4282-7cd4-4436-c496-be7b19bee704"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (DT) Metrics:\n",
            "  Precision: 0.9633\n",
            "  Recall:    0.9722\n",
            "  F1-Score:  0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "max_depth_list = [5, 10, 20, None] # None means no limit (full depth)\n",
        "depth_results = {}\n",
        "\n",
        "print(\"Random Forest Accuracy Comparison by Max Depth:\")\n",
        "for depth in max_depth_list:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42, n_jobs=-1)\n",
        "    rf_clf.fit(X_cls_train, y_cls_train)\n",
        "    y_pred = rf_clf.predict(X_cls_test)\n",
        "    accuracy = accuracy_score(y_cls_test, y_pred)\n",
        "    depth_label = 'None (Full)' if depth is None else str(depth)\n",
        "    depth_results[depth_label] = accuracy\n",
        "    print(f\"Max_Depth={depth_label:<10}: Accuracy={accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PfuwJsj-Spc",
        "outputId": "6a0ecfea-2d3d-43af-9727-d1702a2572a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy Comparison by Max Depth:\n",
            "Max_Depth=5         : Accuracy=0.9649\n",
            "Max_Depth=10        : Accuracy=0.9708\n",
            "Max_Depth=20        : Accuracy=0.9708\n",
            "Max_Depth=None (Full): Accuracy=0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
        "\n",
        "# 1. Decision Tree Base Estimator (already calculated in Q22)\n",
        "mse_dt_base = mse_bag_reg\n",
        "\n",
        "# 2. KNeighbors Regressor Base Estimator\n",
        "knn_base = KNeighborsRegressor(n_neighbors=5)\n",
        "bag_reg_knn = BaggingRegressor(\n",
        "    estimator=knn_base,\n",
        "    n_estimators=100,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "bag_reg_knn.fit(X_reg_train, y_reg_train)\n",
        "y_pred_bag_knn = bag_reg_knn.predict(X_reg_test)\n",
        "mse_knn_base = mean_squared_error(y_reg_test, y_pred_bag_knn)\n",
        "\n",
        "print(f\"Bagging Regressor (DT Base) MSE:   {mse_dt_base:.4f}\")\n",
        "print(f\"Bagging Regressor (KNN Base) MSE: {mse_knn_base:.4f}\")\n",
        "print(f\"The {'DT Base' if mse_dt_base < mse_knn_base else 'KNN Base'} base estimator performed better (lower MSE is better).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFsFSYKI-UCO",
        "outputId": "dfda9ea6-5683-4e0d-d8db-6afe6f969b17"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor (DT Base) MSE:   722.3321\n",
            "Bagging Regressor (KNN Base) MSE: 1153.6753\n",
            "The DT Base base estimator performed better (lower MSE is better).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
        "rf_clf_auc = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf_auc.fit(X_cls_train, y_cls_train)\n",
        "\n",
        "# Get probability scores for the positive class (class 1)\n",
        "y_proba_rf = rf_clf_auc.predict_proba(X_cls_test)[:, 1]\n",
        "auc_rf = roc_auc_score(y_cls_test, y_proba_rf)\n",
        "\n",
        "print(f\"Random Forest Classifier ROC-AUC Score: {auc_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO5MN9Bt-VaL",
        "outputId": "46324e22-fcee-411c-c95a-6a1110ea4cd8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier ROC-AUC Score: 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 42. Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
        "bag_clf_cv = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=50,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "cv_scores = cross_val_score(bag_clf_cv, X_cls, y_cls, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "print(f\"Bagging Classifier Cross-Validation Accuracy Scores (5-fold): {cv_scores}\")\n",
        "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Std Dev of CV Accuracy: {cv_scores.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDWRSTjn-XQ8",
        "outputId": "21b4352d-0457-444e-8ff6-ae97ca08b6d2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Cross-Validation Accuracy Scores (5-fold): [0.9122807  0.92105263 0.98245614 0.95614035 1.        ]\n",
            "Mean CV Accuracy: 0.9544\n",
            "Std Dev of CV Accuracy: 0.0339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 43. Train a Random Forest Classifier and plot the Precision-Recall curve\n",
        "rf_clf_prc = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clf_prc.fit(X_cls_train, y_cls_train)\n",
        "\n",
        "# Get probability scores for the positive class\n",
        "y_proba_prc = rf_clf_prc.predict_proba(X_cls_test)[:, 1]\n",
        "\n",
        "# Calculate Precision and Recall for various thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_cls_test, y_proba_prc)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plotting the curve\n",
        "try:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, label=f'Random Forest (AUC = {pr_auc:.4f})')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid(True)\n",
        "    # plt.show() # Uncomment to display the plot\n",
        "    print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
        "    print(\"Precision-Recall curve plot generated (requires plt.show() to display).\")\n",
        "except Exception as e:\n",
        "    print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
        "    print(f\"Could not display plot due to environment issue (e.g., missing GUI): {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "0ifzCl4S-YrT",
        "outputId": "4341dfd5-2e0f-4bdb-e9be-210e1e4595a4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision-Recall AUC: 0.9982\n",
            "Precision-Recall curve plot generated (requires plt.show() to display).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
        "# Use scaled data for Logistic Regression\n",
        "estimators_rf_lr = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)),\n",
        "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
        "]\n",
        "\n",
        "# The final estimator (meta-model)\n",
        "stack_clf_rf_lr = StackingClassifier(\n",
        "    estimators=estimators_rf_lr,\n",
        "    final_estimator=LogisticRegression(random_state=42),\n",
        "    cv=3,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit using scaled data as one base estimator is LR\n",
        "stack_clf_rf_lr.fit(X_cls_train_scaled, y_cls_train)\n",
        "y_pred_stack_rf_lr = stack_clf_rf_lr.predict(X_cls_test_scaled)\n",
        "accuracy_stack_rf_lr = accuracy_score(y_cls_test, y_pred_stack_rf_lr)\n",
        "\n",
        "# Compare with the Bagging DT accuracy from Q21\n",
        "print(f\"Stacking Classifier (RF+LR) Accuracy: {accuracy_stack_rf_lr:.4f}\")\n",
        "print(f\"Bagging Classifier (DT) Accuracy:     {accuracy_bag_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1ahYfj9-aUl",
        "outputId": "2fd5c0a6-2404-4910-94f4-13f6dca1563e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier (RF+LR) Accuracy: 0.9766\n",
            "Bagging Classifier (DT) Accuracy:     0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "max_samples_list = [0.5, 0.75, 1.0]\n",
        "samples_results = {}\n",
        "base_reg = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "print(\"Bagging Regressor MSE Comparison by Max Samples (Bootstrap Size):\")\n",
        "for ms in max_samples_list:\n",
        "    bag_reg_ms = BaggingRegressor(\n",
        "        estimator=base_reg,\n",
        "        n_estimators=100,\n",
        "        max_samples=ms,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    bag_reg_ms.fit(X_reg_train, y_reg_train)\n",
        "    y_pred = bag_reg_ms.predict(X_reg_test)\n",
        "    mse = mean_squared_error(y_reg_test, y_pred)\n",
        "    samples_results[ms] = mse\n",
        "    print(f\"Max_Samples={ms:.2f}: MSE={mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlU1_IbO-b9J",
        "outputId": "0008f27d-52c1-4fc3-ad42-f1e418af8b3a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE Comparison by Max Samples (Bootstrap Size):\n",
            "Max_Samples=0.50: MSE=735.2602\n",
            "Max_Samples=0.75: MSE=743.0196\n",
            "Max_Samples=1.00: MSE=722.3321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XR4t7Am-dT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}